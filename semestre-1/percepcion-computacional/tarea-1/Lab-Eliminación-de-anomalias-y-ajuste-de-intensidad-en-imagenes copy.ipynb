{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte: Eliminación de Anomalías y Ajuste de Intensidad en Imágenes\n",
    "\n",
    "## Información General\n",
    "**Alumno:** Serguei Drago Dominguez Ruiz  \n",
    "**Asignatura:** Percepción Computacional  \n",
    "**Fecha:** Marzo 2024\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "### 1.1 Objetivos del Laboratorio\n",
    "El presente trabajo tiene como objetivos principales:\n",
    "- Familiarización con técnicas de eliminación de anomalías (ruido)\n",
    "- Implementación de métodos de ajuste de intensidad (contraste)\n",
    "- Desarrollo de soluciones propias y comparación con métodos de OpenCV\n",
    "- Análisis cuantitativo y cualitativo de los resultados\n",
    "\n",
    "### 1.2 Metodología\n",
    "Se seguirá un enfoque sistemático que incluye:\n",
    "1. Implementación de algoritmos propios\n",
    "2. Utilización de funciones de OpenCV\n",
    "3. Evaluación comparativa de resultados\n",
    "4. Análisis de métricas de rendimiento\n",
    "\n",
    "## 2. Eliminación de Anomalías (Criterios 1 y 3)\n",
    "\n",
    "### 2.1 Selección de Imágenes Base\n",
    "Para este estudio, se utilizarán:\n",
    "- Dos imágenes limpias (sin ruido) como base\n",
    "- Visualización mediante `matplotlib.pyplot.imshow`\n",
    "- Análisis de características iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instalación de librerías necesarias\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def instalar_librerias():\n",
    "    packages = [\n",
    "        'numpy>=1.24.0',\n",
    "        'pandas>=2.0.0',\n",
    "        'matplotlib>=3.7.0',\n",
    "        'seaborn>=0.12.0',\n",
    "        'opencv-python>=4.8.0',\n",
    "        'scikit-image>=0.21.0'\n",
    "    ]\n",
    "    \n",
    "    print(\"Instalando las librerías necesarias...\")\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✓ {package} instalado correctamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error instalando {package}: {str(e)}\")\n",
    "    print(\"\\n¡Instalación completada! Ya puedes ejecutar el resto del notebook.\")\n",
    "\n",
    "# Ejecutar la instalación\n",
    "#instalar_librerias()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar las imágenes\n",
    "img1 = cv2.imread('images/Cars34.png')\n",
    "img2 = cv2.imread('images/coche01.jpeg')\n",
    "\n",
    "# Convertir a escala de grises\n",
    "if len(img1.shape) == 3:\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "if len(img2.shape) == 3:\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "def mostrar_imagenes(img1, img2, titulo1='Cars34.png', titulo2='coche01.jpeg'):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(titulo1)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(titulo2)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "mostrar_imagenes(img1, img2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Implementación de Ruido Artificial\n",
    "\n",
    "#### 2.2.1 Ruido Sal y Pimienta\n",
    "Se implementará una función personalizada para simular el ruido de sal y pimienta, uno de los tipos más comunes de ruido en imágenes digitales.\n",
    "\n",
    "**Características del algoritmo:**\n",
    "1. **Preservación de datos originales**\n",
    "   - Creación de una copia de la imagen original\n",
    "   - Manipulación no destructiva de los datos\n",
    "\n",
    "2. **Generación de ruido**\n",
    "   - Uso de máscaras aleatorias mediante `np.random.random`\n",
    "   - Distribución equitativa entre ruido de sal (255) y pimienta (0)\n",
    "   - Control de densidad mediante parámetro de probabilidad\n",
    "\n",
    "3. **Implementación técnica**\n",
    "   - Utilización de arrays NumPy para eficiencia computacional\n",
    "   - Manipulación matricial para optimización de rendimiento\n",
    "   - Preservación de tipos de datos y rangos de valores\n",
    "\n",
    "> **Nota técnica:** Se utiliza `numpy.ndarray` como estructura de datos principal por su eficiencia en operaciones matriciales y gestión de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_pepper(image, prob=0.05):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image (numpy.ndarray): Imagen de entrada en escala de grises\n",
    "        prob (float, optional): Probabilidad total de ruido. Por defecto 0.05 (5%)\n",
    "    Returns:\n",
    "        numpy.ndarray: Imagen con ruido de sal y pimienta\n",
    "    \"\"\"\n",
    "    noisy = np.copy(image)\n",
    "    # Generar máscaras aleatorias para sal (255) y pimienta (0)\n",
    "    # np.random.random genera un array de números aleatorios entre 0 y 1 con la misma forma que image.shape[:2] (100x200 por ejemplo)\n",
    "    # La comparación < prob/2 crea una máscara booleana donde True indica dónde agregar ruido de sal y pimienta\n",
    "    salt_mask = np.random.random(image.shape[:2]) < prob/2\n",
    "    pepper_mask = np.random.random(image.shape[:2]) < prob/2\n",
    "    noisy[salt_mask] = 255\n",
    "    noisy[pepper_mask] = 0\n",
    "    return noisy\n",
    "\n",
    "# Aplicar ruido a las imágenes\n",
    "noisy_img1 = add_salt_pepper(img1)\n",
    "noisy_img2 = add_salt_pepper(img2)\n",
    "\n",
    "\n",
    "def mostrar_imagenes_ruido(img1, img2, titulo1='Cars34.png con ruido', titulo2='coche01.jpeg con ruido'):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(titulo1)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(titulo2)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "mostrar_imagenes_ruido(noisy_img1, noisy_img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Técnica de Eliminación de Ruido - Desarrollo Propio\n",
    "\n",
    "#### 2.3.1 Filtro de Mediana Personalizado\n",
    "En esta sección se presenta la implementación de un filtro de mediana desarrollado desde cero. Este filtro es especialmente efectivo para la eliminación del ruido tipo \"sal y pimienta\" debido a su naturaleza no lineal y su capacidad para preservar bordes.\n",
    "\n",
    "#### 2.3.2 Fundamento Teórico\n",
    "El filtro de mediana se basa en un principio de procesamiento local de la imagen:\n",
    "\n",
    "1. **Análisis por Ventana**\n",
    "   - Definición de ventana de vecindad (3x3 píxeles)\n",
    "   - Procesamiento secuencial de cada píxel\n",
    "\n",
    "2. **Proceso de Filtrado**\n",
    "   - Ordenamiento de valores en la ventana\n",
    "   - Selección del valor mediano\n",
    "   - Asignación al píxel central\n",
    "\n",
    "3. **Iteración Completa**\n",
    "   - Aplicación sistemática a toda la imagen\n",
    "   - Preservación de información estructural\n",
    "\n",
    "#### 2.3.3 Características de la Implementación\n",
    "\n",
    "1. **Gestión de Bordes**\n",
    "   - Enfoque conservador en píxeles periféricos\n",
    "   - Mantenimiento de valores originales en bordes\n",
    "   - Prevención de artefactos en límites\n",
    "\n",
    "2. **Flexibilidad Operativa**\n",
    "   - Parámetro `k` configurable para tamaño de ventana\n",
    "   - Adaptabilidad a diferentes tipos de ruido\n",
    "   - Balance entre filtrado y preservación de detalles\n",
    "\n",
    "3. **Preservación de Estructuras**\n",
    "   - Uso de mediana vs. promedio\n",
    "   - Mejor conservación de bordes\n",
    "   - Reducción de desenfoque en transiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_mediana_manual(imagen, k=3):\n",
    "    \"\"\"\n",
    "    Aplica un filtro de mediana manualmente sin usar funciones de OpenCV.\n",
    "    \n",
    "    Args:\n",
    "        imagen (numpy.ndarray): Imagen de entrada en escala de grises\n",
    "        k (int): Tamaño de la ventana del filtro (debe ser impar)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Imagen filtrada\n",
    "    \"\"\"\n",
    "    # Asegurarse que k sea impar\n",
    "    if k % 2 == 0:\n",
    "        k = k + 1\n",
    "    \n",
    "    # Crear una copia de la imagen para el resultado\n",
    "    altura, anchura = imagen.shape\n",
    "    imagen_filtrada = np.zeros_like(imagen)\n",
    "    \n",
    "    # Calcular el padding necesario\n",
    "    pad = k // 2\n",
    "    \n",
    "    # Aplicar el filtro de mediana\n",
    "    for i in range(pad, altura - pad):\n",
    "        for j in range(pad, anchura - pad):\n",
    "            # Obtener la ventana de vecindad\n",
    "            ventana = imagen[i-pad:i+pad+1, j-pad:j+pad+1]\n",
    "            # Calcular la mediana de la ventana\n",
    "            mediana = np.median(ventana)\n",
    "            # Asignar el valor de la mediana al píxel central\n",
    "            imagen_filtrada[i, j] = mediana\n",
    "    \n",
    "    return imagen_filtrada\n",
    "\n",
    "# Aplicar el filtro de mediana manual a ambas imágenes\n",
    "img1_filtrada_manual = filtro_mediana_manual(noisy_img1)\n",
    "img2_filtrada_manual = filtro_mediana_manual(noisy_img2)\n",
    "\n",
    "\n",
    "def mostrar_resultados(noisy_img1, img1_filtrada_manual, img1, noisy_img2, img2_filtrada_manual, img2):\n",
    "    \"\"\"\n",
    "    Muestra las imágenes originales, con ruido y filtradas en una figura.\n",
    "    \n",
    "    Args:\n",
    "        noisy_img1, noisy_img2: Imágenes con ruido\n",
    "        img1_filtrada_manual, img2_filtrada_manual: Imágenes filtradas\n",
    "        img1, img2: Imágenes originales\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Imagen 1\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(noisy_img1, cmap='gray')\n",
    "    plt.title('Imagen 1 con ruido')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(img1_filtrada_manual, cmap='gray')\n",
    "    plt.title('Imagen 1 filtrada algoritmo propio')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title('Imagen 1 original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Imagen 2\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(noisy_img2, cmap='gray')\n",
    "    plt.title('Imagen 2 con ruido')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(img2_filtrada_manual, cmap='gray')\n",
    "    plt.title('Imagen 2 filtrada algoritmo propio')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title('Imagen 2 original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "mostrar_resultados(noisy_img1, img1_filtrada_manual, img1, noisy_img2, img2_filtrada_manual, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Técnica de Eliminación de Ruido - Implementación OpenCV\n",
    "\n",
    "#### 2.4.1 Descripción General\n",
    "La segunda implementación aprovecha la función `cv2.medianBlur()` de OpenCV, una biblioteca profesional altamente optimizada para procesamiento de imágenes. Esta implementación ofrece ventajas significativas en términos de rendimiento y eficiencia.\n",
    "\n",
    "#### 2.4.2 Características Técnicas\n",
    "\n",
    "1. **Optimizaciones de Bajo Nivel**\n",
    "   - Implementación en C++ altamente optimizada\n",
    "   - Aprovechamiento de instrucciones SIMD\n",
    "   - Paralelización eficiente de operaciones\n",
    "   - Optimización de acceso a memoria\n",
    "\n",
    "2. **Gestión Avanzada de Bordes**\n",
    "   - Sistema inteligente de padding\n",
    "   - Preservación mejorada de bordes y detalles\n",
    "   - Reducción de artefactos en límites\n",
    "   - Manejo adaptativo de regiones frontera\n",
    "\n",
    "3. **Ventajas de Rendimiento**\n",
    "   - Ejecución significativamente más rápida\n",
    "   - Gestión eficiente de recursos de memoria\n",
    "   - Aprovechamiento óptimo del hardware\n",
    "   - Escalabilidad para imágenes de gran tamaño\n",
    "\n",
    "#### 2.4.3 Beneficios Prácticos\n",
    "- **Velocidad:** Ideal para aplicaciones en tiempo real\n",
    "- **Robustez:** Manejo consistente de casos extremos\n",
    "- **Eficiencia:** Menor consumo de recursos del sistema\n",
    "- **Precisión:** Resultados de alta calidad y confiabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el filtro de mediana de OpenCV\n",
    "\"\"\"\n",
    "OpenCV proporciona una implementación optimizada del filtro de mediana a través de cv2.medianBlur.\n",
    "Esta función es significativamente más rápida que la implementación manual debido a:\n",
    "1. Optimizaciones a nivel de código C++\n",
    "2. Posible uso de instrucciones SIMD\n",
    "3. Manejo eficiente de los bordes de la imagen\n",
    "\n",
    "Parámetros:\n",
    "- ksize: Tamaño de la ventana del kernel (debe ser impar). Este parámetro determina el tamaño del área vecina que se analiza para calcular la mediana. Por ejemplo:\n",
    "  - ksize=3: Analiza una ventana de 3x3 píxeles\n",
    "  - ksize=5: Analiza una ventana de 5x5 píxeles\n",
    "  - ksize=7: Analiza una ventana de 7x7 píxeles\n",
    "  Un valor más grande eliminará más ruido pero puede suavizar demasiado los detalles de la imagen.\n",
    "\"\"\"\n",
    "\n",
    "# Aplicar el filtro a ambas imágenes\n",
    "img1_filtrada_opencv = cv2.medianBlur(noisy_img1, ksize=3)\n",
    "img2_filtrada_opencv = cv2.medianBlur(noisy_img2, ksize=3)\n",
    "\n",
    "# Medir tiempos de ejecución\n",
    "import time\n",
    "\n",
    "# Medir tiempo para el filtro manual\n",
    "start_time = time.time()\n",
    "_ = filtro_mediana_manual(noisy_img1)\n",
    "tiempo_manual = time.time() - start_time\n",
    "\n",
    "# Medir tiempo para OpenCV\n",
    "start_time = time.time()\n",
    "_ = cv2.medianBlur(noisy_img1, ksize=3)\n",
    "tiempo_opencv = time.time() - start_time\n",
    "\n",
    "def plot_comparison(noisy_img1, img1_filtrada_opencv, img1, noisy_img2, img2_filtrada_opencv, img2, tiempo_manual, tiempo_opencv):\n",
    "    plt.figure(figsize=(15, 11))\n",
    "    \n",
    "    # Primera fila: Imagen 1\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(noisy_img1, cmap='gray')\n",
    "    plt.title('Imagen 1 con ruido')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(img1_filtrada_opencv, cmap='gray')\n",
    "    plt.title('Filtro mediana OpenCV')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title('Imagen 1 original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Segunda fila: Imagen 2\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(noisy_img2, cmap='gray')\n",
    "    plt.title('Imagen 2 con ruido')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(img2_filtrada_opencv, cmap='gray')\n",
    "    plt.title('Filtro mediana OpenCV')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title('Imagen 2 original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Tercera fila: Información de rendimiento\n",
    "    plt.subplot(412)\n",
    "    plt.axis('off')\n",
    "    plt.text(0.5, .25,\n",
    "            'Comparación de Rendimiento\\n' +\n",
    "            f'Tiempo implementación manual: {tiempo_manual:.4f} segundos\\n' +\n",
    "            f'Tiempo implementación OpenCV: {tiempo_opencv:.4f} segundos\\n' +\n",
    "            f'OpenCV es {tiempo_manual/tiempo_opencv:.1f}x más rápido',\n",
    "            ha='center', va='center', fontsize=12,\n",
    "            bbox=dict(facecolor='white', alpha=0.9, edgecolor='gray', pad=10))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "plot_comparison(noisy_img1, img1_filtrada_opencv, img1, noisy_img2, img2_filtrada_opencv, img2, tiempo_manual, tiempo_opencv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluación Cuantitativa del Rendimiento (Criterio 3)\n",
    "\n",
    "#### 2.5.1 Metodología de Evaluación\n",
    "Para realizar una evaluación objetiva y sistemática de la calidad de restauración de imágenes, se implementaron dos métricas complementarias de evaluación cuantitativa.\n",
    "\n",
    "#### 2.5.2 Métricas Implementadas\n",
    "\n",
    "1. **PSNR (Peak Signal-to-Noise Ratio)**\n",
    "   \n",
    "   *Descripción:* Métrica fundamental que evalúa la calidad de la señal restaurada.\n",
    "   \n",
    "   **Características principales:**\n",
    "   - Medición de la relación señal/ruido\n",
    "   - Expresión en decibeles (dB)\n",
    "   - Correlación con calidad visual\n",
    "   \n",
    "   **Interpretación:**\n",
    "   - Valores más altos → Mejor calidad\n",
    "   - Rango típico: 20-40 dB\n",
    "   - Referencia estándar en procesamiento de imágenes\n",
    "\n",
    "2. **SSIM (Structural Similarity Index)**\n",
    "   \n",
    "   *Descripción:* Métrica avanzada que evalúa la similitud perceptual entre imágenes.\n",
    "   \n",
    "   **Componentes de análisis:**\n",
    "   - Luminancia\n",
    "   - Contraste\n",
    "   - Estructura\n",
    "   \n",
    "   **Características clave:**\n",
    "   - Rango de valores: [-1, 1]\n",
    "   - Valor 1 → Imágenes idénticas\n",
    "   - Superior a PSNR en correlación con percepción humana\n",
    "\n",
    "#### 2.5.3 Proceso de Evaluación\n",
    "\n",
    "**Comparaciones realizadas:**\n",
    "1. Imagen original vs. Filtrado manual\n",
    "   - Evaluación de efectividad del algoritmo propio\n",
    "   - Análisis de preservación de detalles\n",
    "\n",
    "2. Imagen original vs. Filtrado OpenCV\n",
    "   - Evaluación de la implementación profesional\n",
    "   - Benchmark de calidad\n",
    "\n",
    "**Métricas adicionales:**\n",
    "- Tiempo de procesamiento\n",
    "- Uso de recursos computacionales\n",
    "- Escalabilidad del método\n",
    "\n",
    "#### 2.5.4 Presentación de Resultados\n",
    "Los resultados se organizan en una tabla comparativa que incluye:\n",
    "- Valores PSNR y SSIM para cada método\n",
    "- Tiempos de ejecución\n",
    "- Análisis comparativo de rendimiento\n",
    "- Recomendaciones basadas en los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calcular PSNR y SSIM para ambas imágenes y ambos métodos\n",
    "metrics = {\n",
    "    'Imagen': [],\n",
    "    'Método': [],\n",
    "    'PSNR (dB)': [],\n",
    "    'SSIM': [],\n",
    "    'Tiempo (s)': []\n",
    "}\n",
    "\n",
    "# Calcular métricas para la primera imagen\n",
    "psnr_manual_1 = peak_signal_noise_ratio(img1, img1_filtrada_manual)\n",
    "psnr_opencv_1 = peak_signal_noise_ratio(img1, img1_filtrada_opencv)\n",
    "ssim_manual_1 = ssim(img1, img1_filtrada_manual)\n",
    "ssim_opencv_1 = ssim(img1, img1_filtrada_opencv)\n",
    "\n",
    "# Calcular métricas para la segunda imagen\n",
    "psnr_manual_2 = peak_signal_noise_ratio(img2, img2_filtrada_manual)\n",
    "psnr_opencv_2 = peak_signal_noise_ratio(img2, img2_filtrada_opencv)\n",
    "ssim_manual_2 = ssim(img2, img2_filtrada_manual)\n",
    "ssim_opencv_2 = ssim(img2, img2_filtrada_opencv)\n",
    "\n",
    "# Agregar resultados al diccionario\n",
    "for img_num, (psnr_m, psnr_o, ssim_m, ssim_o) in enumerate([(psnr_manual_1, psnr_opencv_1, ssim_manual_1, ssim_opencv_1),\n",
    "                                                           (psnr_manual_2, psnr_opencv_2, ssim_manual_2, ssim_opencv_2)], 1):\n",
    "    metrics['Imagen'].extend([f'Imagen {img_num}', f'Imagen {img_num}'])\n",
    "    metrics['Método'].extend(['Manual', 'OpenCV'])\n",
    "    metrics['PSNR (dB)'].extend([round(psnr_m, 4), round(psnr_o, 4)])\n",
    "    metrics['SSIM'].extend([round(ssim_m, 4), round(ssim_o, 4)])\n",
    "    metrics['Tiempo (s)'].extend([round(tiempo_manual, 4), round(tiempo_opencv, 4)])\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "def plot_metrics_analysis(df, tiempo_manual, tiempo_opencv):\n",
    "    # Crear figura con subplots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.suptitle('Análisis Comparativo de Métricas', fontsize=16, y=0.95)\n",
    "\n",
    "    # 1. Tabla de métricas\n",
    "    plt.subplot(221)\n",
    "    plt.axis('off')\n",
    "    table = plt.table(cellText=df.values,\n",
    "                     colLabels=df.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colColours=['#f2f2f2']*5)\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.2, 1.5)\n",
    "    plt.title('Tabla Comparativa de Métricas')\n",
    "\n",
    "    # 2. Gráfico de barras para PSNR\n",
    "    plt.subplot(222)\n",
    "    sns.barplot(data=df, x='Imagen', y='PSNR (dB)', hue='Método')\n",
    "    plt.title('Comparación PSNR')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # 3. Gráfico de barras para SSIM\n",
    "    plt.subplot(223)\n",
    "    sns.barplot(data=df, x='Imagen', y='SSIM', hue='Método')\n",
    "    plt.title('Comparación SSIM')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # 4. Gráfico de barras para Tiempo\n",
    "    plt.subplot(224)\n",
    "    sns.barplot(data=df, x='Imagen', y='Tiempo (s)', hue='Método')\n",
    "    plt.title('Comparación de Tiempo de Ejecución')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Mostrar conclusión\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.axis('off')\n",
    "    conclusion_text = (\n",
    "        \"Conclusión:\\n\\n\"\n",
    "        \"1. Rendimiento temporal: OpenCV es significativamente más rápido, siendo aproximadamente \"\n",
    "        f\"{tiempo_manual/tiempo_opencv:.1f}x más veloz que la implementación manual.\\n\\n\"\n",
    "        \"2. Calidad de restauración:\\n\"\n",
    "        f\"   - PSNR: OpenCV logra valores más altos en promedio ({round(df[df['Método']=='OpenCV']['PSNR (dB)'].mean(), 4)} dB vs \"\n",
    "        f\"{round(df[df['Método']=='Manual']['PSNR (dB)'].mean(), 4)} dB)\\n\"\n",
    "        f\"   - SSIM: OpenCV mantiene mejor la estructura de la imagen ({round(df[df['Método']=='OpenCV']['SSIM'].mean(), 4)} vs \"\n",
    "        f\"{round(df[df['Método']=='Manual']['SSIM'].mean(), 4)})\\n\\n\"\n",
    "        \"3. Optimización: La implementación de OpenCV utiliza código C++ optimizado y posiblemente instrucciones SIMD,\\n\"\n",
    "        \"   resultando en un mejor balance entre calidad de restauración y eficiencia computacional.\"\n",
    "    )\n",
    "    plt.text(0, 0.5, conclusion_text, ha='left', va='center', fontsize=10,\n",
    "             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8, pad=10))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "plot_metrics_analysis(df, tiempo_manual, tiempo_opencv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajuste de Intensidad (Criterios 2 y 4)\n",
    "\n",
    "### 3.1 Introducción al Ajuste de Intensidad\n",
    "\n",
    "#### 3.1.1 Objetivo del Proceso\n",
    "El ajuste de intensidad es una técnica fundamental en el procesamiento de imágenes que busca mejorar la calidad visual y el contraste de imágenes subóptimas. Este proceso es especialmente relevante cuando:\n",
    "- Las imágenes presentan bajo contraste\n",
    "- La distribución de intensidades es desigual\n",
    "- Los detalles importantes son difíciles de distinguir\n",
    "\n",
    "#### 3.1.2 Metodología de Trabajo\n",
    "Para este estudio se seguirá un proceso sistemático que incluye:\n",
    "1. Selección cuidadosa de imágenes de prueba\n",
    "2. Aplicación de técnicas de mejora de contraste\n",
    "3. Evaluación objetiva de resultados\n",
    "4. Análisis comparativo de métodos\n",
    "\n",
    "#### 3.1.3 Selección de Imágenes\n",
    "Se han seleccionado específicamente dos imágenes que presentan desafíos de contraste:\n",
    "- **Imagen 1:** `coche11.jpeg` - Ejemplo de bajo contraste general\n",
    "- **Imagen 2:** `coche02.jpeg` - Caso de distribución de intensidad subóptima\n",
    "\n",
    "Estas imágenes fueron elegidas por presentar características ideales para demostrar la efectividad de las técnicas de ajuste de intensidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Cargar las imágenes de bajo contraste\n",
    "img_low1 = cv2.imread('images/coche11.jpeg')\n",
    "img_low2 = cv2.imread('images/coche02.jpeg')\n",
    "\n",
    "# Convertir a escala de grises\n",
    "if len(img_low1.shape) == 3:\n",
    "    img_low1_gray = cv2.cvtColor(img_low1, cv2.COLOR_BGR2GRAY)\n",
    "if len(img_low2.shape) == 3:\n",
    "    img_low2_gray = cv2.cvtColor(img_low2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def mostrar_imagenes_histogramas(img1, img2, titulo1=\"Imagen 1\", titulo2=\"Imagen 2\"):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Primera imagen y su histograma\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(f'{titulo1}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.hist(img1.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title(f'Histograma {titulo1}')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    # Segunda imagen y su histograma\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(f'{titulo2}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.hist(img2.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title(f'Histograma {titulo2}')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función con las imágenes\n",
    "mostrar_imagenes_histogramas(img_low1_gray, img_low2_gray, \n",
    "                           \"Imagen 1: coche11.jpeg\", \n",
    "                           \"Imagen 2: coche02.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. **Aplicación de dos técnicas para mejorar el contraste:**\n",
    "\n",
    "### 3.2 Técnicas de Ajuste de Intensidad\n",
    "\n",
    "#### 3.2.1 Ecualización de Histograma - Implementación Propia\n",
    "\n",
    "La ecualización de histograma es una técnica fundamental para la mejora de contraste en imágenes digitales. Nuestra implementación personalizada, `ecualizacion_histograma_manual`, sigue un proceso metódico y matemáticamente fundamentado.\n",
    "\n",
    "##### A. Proceso de Implementación\n",
    "\n",
    "1. **Análisis de Histograma**\n",
    "   - *Objetivo:* Obtener la distribución de intensidades\n",
    "   - *Método:* \n",
    "     * Creación de array de 256 elementos\n",
    "     * Conteo de frecuencias por nivel de intensidad\n",
    "   - *Resultado:* Histograma inicial de la imagen\n",
    "\n",
    "2. **Función de Distribución Acumulativa (CDF)**\n",
    "   - *Cálculo:* Suma acumulativa del histograma\n",
    "   - *Significado:* Probabilidad acumulada por nivel\n",
    "   - *Importancia:* Base para la transformación de intensidades\n",
    "\n",
    "3. **Proceso de Normalización**\n",
    "   - *Fórmula:* `(cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())`\n",
    "   - *Rango:* Ajuste al intervalo [0, 255]\n",
    "   - *Tipo:* Conversión a uint8 para compatibilidad\n",
    "\n",
    "4. **Transformación de Intensidades**\n",
    "   - *Método:* Mapeo mediante tabla de búsqueda\n",
    "   - *Proceso:* Reasignación de valores de píxeles\n",
    "   - *Resultado:* Distribución uniforme de intensidades\n",
    "\n",
    "##### B. Beneficios del Método\n",
    "- **Mejora de Contraste:** Distribución optimizada de intensidades\n",
    "- **Preservación de Información:** Mantenimiento de relaciones relativas\n",
    "- **Automatización:** No requiere parámetros de ajuste manual\n",
    "- **Adaptabilidad:** Funciona con diversos tipos de imágenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecualizacion_histograma_manual(imagen):\n",
    "    \"\"\"\n",
    "    Implementación manual de ecualización de histograma.\n",
    "    \n",
    "    Args:\n",
    "        imagen (numpy.ndarray): Imagen en escala de grises\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Imagen con histograma ecualizado\n",
    "    \"\"\"\n",
    "    # Obtener dimensiones de la imagen\n",
    "    altura, anchura = imagen.shape\n",
    "    total_pixeles = altura * anchura\n",
    "    \n",
    "    # Calcular histograma\n",
    "    histograma = np.zeros(256)\n",
    "    for i in range(altura):\n",
    "        for j in range(anchura):\n",
    "            histograma[imagen[i,j]] += 1\n",
    "            \n",
    "    # Calcular CDF (Cumulative Distribution Function)\n",
    "    cdf = np.cumsum(histograma)\n",
    "    \n",
    "    # Normalizar CDF\n",
    "    cdf_normalizado = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
    "    cdf_normalizado = cdf_normalizado.astype(np.uint8)\n",
    "    \n",
    "    # Crear imagen ecualizada usando el mapeo del CDF\n",
    "    imagen_ecualizada = cdf_normalizado[imagen]\n",
    "    \n",
    "    return imagen_ecualizada\n",
    "\n",
    "# Aplicar ecualización manual a ambas imágenes\n",
    "img1_eq_manual = ecualizacion_histograma_manual(img_low1_gray)\n",
    "img2_eq_manual = ecualizacion_histograma_manual(img_low2_gray)\n",
    "\n",
    "\n",
    "def visualizar_resultados(img_orig1, img_eq1, img_orig2, img_eq2):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Primera imagen\n",
    "    plt.subplot(421)\n",
    "    plt.imshow(img_orig1, cmap='gray')\n",
    "    plt.title('Imagen 1 Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(422)\n",
    "    plt.hist(img_orig1.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Original')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.subplot(423)\n",
    "    plt.imshow(img_eq1, cmap='gray')\n",
    "    plt.title('Imagen 1 Ecualizada (Manual)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(424)\n",
    "    plt.hist(img_eq1.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Ecualizado')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    # Segunda imagen\n",
    "    plt.subplot(425)\n",
    "    plt.imshow(img_orig2, cmap='gray')\n",
    "    plt.title('Imagen 2 Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(426)\n",
    "    plt.hist(img_orig2.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Original')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.subplot(427)\n",
    "    plt.imshow(img_eq2, cmap='gray')\n",
    "    plt.title('Imagen 2 Ecualizada (Manual)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(428)\n",
    "    plt.hist(img_eq2.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Ecualizado')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la visualización\n",
    "visualizar_resultados(img_low1_gray, img1_eq_manual, img_low2_gray, img2_eq_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Ecualización de Histograma - Implementación OpenCV\n",
    "\n",
    "La segunda aproximación al ajuste de intensidad utiliza la función `cv2.equalizeHist` de OpenCV, una implementación profesional y optimizada de la ecualización de histograma.\n",
    "\n",
    "##### A. Características de la Implementación\n",
    "\n",
    "1. **Fundamentos Técnicos**\n",
    "   - *Biblioteca:* OpenCV (Open Computer Vision)\n",
    "   - *Función:* `cv2.equalizeHist`\n",
    "   - *Optimización:* Código nativo en C++\n",
    "\n",
    "2. **Ventajas del Método**\n",
    "   - *Rendimiento:* Ejecución altamente optimizada\n",
    "   - *Robustez:* Manejo eficiente de casos extremos\n",
    "   - *Precisión:* Resultados consistentes y confiables\n",
    "\n",
    "3. **Proceso de Ecualización**\n",
    "   - *Entrada:* Imagen en escala de grises\n",
    "   - *Transformación:* Redistribución uniforme de intensidades\n",
    "   - *Salida:* Imagen con contraste mejorado\n",
    "\n",
    "##### B. Aplicaciones Prácticas\n",
    "- **Procesamiento en Tiempo Real**\n",
    "- **Análisis de Imágenes Médicas**\n",
    "- **Sistemas de Visión Artificial**\n",
    "- **Fotografía Digital**\n",
    "\n",
    "##### C. Consideraciones de Uso\n",
    "- Ideal para aplicaciones que requieren alto rendimiento\n",
    "- Excelente para procesamiento por lotes\n",
    "- Solución robusta para sistemas en producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3.3 Técnica de ajuste (2) – **OpenCV**\n",
    "\n",
    "# Aplicar ecualización de histograma con OpenCV\n",
    "img1_eq_opencv = cv2.equalizeHist(img_low1_gray)\n",
    "img2_eq_opencv = cv2.equalizeHist(img_low2_gray)\n",
    "\n",
    "\n",
    "def visualizar_comparacion_opencv(img_orig1, img_eq1, img_orig2, img_eq2):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Primera imagen\n",
    "    plt.subplot(421)\n",
    "    plt.imshow(img_orig1, cmap='gray')\n",
    "    plt.title('Imagen 1 Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(422)\n",
    "    plt.hist(img_orig1.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Original')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.subplot(423)\n",
    "    plt.imshow(img_eq1, cmap='gray')\n",
    "    plt.title('Imagen 1 Ecualizada (OpenCV)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(424)\n",
    "    plt.hist(img_eq1.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Ecualizado (OpenCV)')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    # Segunda imagen\n",
    "    plt.subplot(425)\n",
    "    plt.imshow(img_orig2, cmap='gray')\n",
    "    plt.title('Imagen 2 Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(426)\n",
    "    plt.hist(img_orig2.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Original')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.subplot(427)\n",
    "    plt.imshow(img_eq2, cmap='gray')\n",
    "    plt.title('Imagen 2 Ecualizada (OpenCV)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(428)\n",
    "    plt.hist(img_eq2.ravel(), bins=256, range=[0,256], density=True)\n",
    "    plt.title('Histograma Ecualizado (OpenCV)')\n",
    "    plt.xlabel('Intensidad')\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "visualizar_comparacion_opencv(img_low1_gray, img1_eq_opencv, img_low2_gray, img2_eq_opencv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Análisis y Visualización de Resultados\n",
    "\n",
    "#### 3.3.1 Metodología de Visualización\n",
    "\n",
    "La evaluación visual de los resultados se realiza mediante un análisis sistemático que incluye tanto las imágenes como sus histogramas correspondientes.\n",
    "\n",
    "##### A. Herramientas de Visualización\n",
    "1. **Representación de Imágenes**\n",
    "   - Visualización mediante `matplotlib.pyplot`\n",
    "   - Disposición comparativa de resultados\n",
    "   - Escalado apropiado para análisis detallado\n",
    "\n",
    "2. **Análisis de Histogramas**\n",
    "   - Generación mediante `cv2.calcHist` y `plt.hist`\n",
    "   - Visualización de distribución de intensidades\n",
    "   - Comparación antes/después del procesamiento\n",
    "\n",
    "##### B. Aspectos Evaluados\n",
    "1. **Calidad Visual**\n",
    "   - Mejora general del contraste\n",
    "   - Preservación de detalles\n",
    "   - Ausencia de artefactos\n",
    "\n",
    "2. **Distribución de Intensidades**\n",
    "   - Uniformidad del histograma\n",
    "   - Aprovechamiento del rango dinámico\n",
    "   - Efectividad de la ecualización\n",
    "\n",
    "##### C. Métricas de Comparación\n",
    "- Análisis cuantitativo de histogramas\n",
    "- Evaluación de rangos dinámicos\n",
    "- Medición de mejora de contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3.4 Análisis Comparativo y Conclusiones\n",
    "\n",
    "# Calcular métricas de contraste\n",
    "def calcular_contraste(imagen):\n",
    "    return np.std(imagen)\n",
    "\n",
    "# Calcular tiempo de ejecución para ambos métodos\n",
    "import time\n",
    "\n",
    "# Medir tiempo para implementación manual\n",
    "start_time = time.time()\n",
    "_ = ecualizacion_histograma_manual(img_low1_gray)\n",
    "tiempo_manual = time.time() - start_time\n",
    "\n",
    "# Medir tiempo para OpenCV\n",
    "start_time = time.time()\n",
    "_ = cv2.equalizeHist(img_low1_gray)\n",
    "tiempo_opencv = time.time() - start_time\n",
    "\n",
    "# Crear DataFrame con métricas\n",
    "metrics = {\n",
    "    'Imagen': [],\n",
    "    'Método': [],\n",
    "    'Contraste Original': [],\n",
    "    'Contraste Mejorado': [],\n",
    "    'Mejora de Contraste (%)': [],\n",
    "    'Tiempo (s)': []\n",
    "}\n",
    "\n",
    "# Calcular métricas para ambas imágenes y métodos\n",
    "for img_num, (img_orig, img_manual, img_opencv) in enumerate([(img_low1_gray, img1_eq_manual, img1_eq_opencv),\n",
    "                                                            (img_low2_gray, img2_eq_manual, img2_eq_opencv)], 1):\n",
    "    # Contraste original\n",
    "    contraste_orig = calcular_contraste(img_orig)\n",
    "    \n",
    "    # Método manual\n",
    "    contraste_manual = calcular_contraste(img_manual)\n",
    "    mejora_manual = ((contraste_manual - contraste_orig) / contraste_orig) * 100\n",
    "    \n",
    "    # Método OpenCV\n",
    "    contraste_opencv = calcular_contraste(img_opencv)\n",
    "    mejora_opencv = ((contraste_opencv - contraste_orig) / contraste_orig) * 100\n",
    "    \n",
    "    # Agregar al diccionario\n",
    "    for metodo, contraste, mejora, tiempo in [('Manual', contraste_manual, mejora_manual, tiempo_manual),\n",
    "                                            ('OpenCV', contraste_opencv, mejora_opencv, tiempo_opencv)]:\n",
    "        metrics['Imagen'].append(f'Imagen {img_num}')\n",
    "        metrics['Método'].append(metodo)\n",
    "        metrics['Contraste Original'].append(round(contraste_orig, 2))\n",
    "        metrics['Contraste Mejorado'].append(round(contraste, 2))\n",
    "        metrics['Mejora de Contraste (%)'].append(round(mejora, 2))\n",
    "        metrics['Tiempo (s)'].append(round(tiempo, 4))\n",
    "\n",
    "# Crear DataFrame y mostrar resultados\n",
    "df = pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "def visualizar_resultados(df, tiempo_manual, tiempo_opencv):\n",
    "    # Visualizar resultados\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 1. Tabla de métricas (ocupa dos columnas)\n",
    "    plt.subplot(211)\n",
    "    plt.axis('off')\n",
    "    table = plt.table(cellText=df.values,\n",
    "                     colLabels=df.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colColours=['#f2f2f2']*6)\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.2, 1.5)\n",
    "    plt.title('Tabla Comparativa de Métricas')\n",
    "\n",
    "    # 2. Gráfico de barras para Mejora de Contraste\n",
    "    plt.subplot(223)\n",
    "    sns.barplot(data=df, x='Imagen', y='Mejora de Contraste (%)', hue='Método')\n",
    "    plt.title('Comparación de Mejora de Contraste')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # 3. Gráfico de barras para Tiempo\n",
    "    plt.subplot(224)\n",
    "    sns.barplot(data=df, x='Imagen', y='Tiempo (s)', hue='Método')\n",
    "    plt.title('Comparación de Tiempo de Ejecución')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Ajustar layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Mostrar conclusiones\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.axis('off')\n",
    "    conclusion_text = (\n",
    "        \"Conclusiones del Análisis de Ajuste de Intensidad:\\n\\n\"\n",
    "        \"1. Efectividad en la Mejora de Contraste:\\n\"\n",
    "        f\"   - Implementación Manual: Mejora promedio de {df[df['Método']=='Manual']['Mejora de Contraste (%)'].mean():.2f}%\\n\"\n",
    "        f\"   - OpenCV: Mejora promedio de {df[df['Método']=='OpenCV']['Mejora de Contraste (%)'].mean():.2f}%\\n\\n\"\n",
    "        \"2. Rendimiento Temporal:\\n\"\n",
    "        f\"   - OpenCV es aproximadamente {tiempo_manual/tiempo_opencv:.1f}x más rápido que la implementación manual\\n\"\n",
    "        f\"   - Tiempo promedio OpenCV: {tiempo_opencv*1000:.2f} ms vs Manual: {tiempo_manual*1000:.2f} ms\\n\\n\"\n",
    "        \"3. Características de las Técnicas:\\n\"\n",
    "        \"   - Implementación Manual: Ofrece mayor control sobre el proceso y permite personalización\\n\"\n",
    "        \"   - OpenCV: Implementación optimizada, más eficiente y robusta\\n\\n\"\n",
    "        \"4. Selección de la Mejor Técnica:\\n\"\n",
    "        \"   - Para aplicaciones en tiempo real: OpenCV es la mejor opción por su velocidad\\n\"\n",
    "        \"   - Para procesamiento por lotes o cuando se requiere personalización: La implementación manual puede ser preferible\\n\"\n",
    "        \"   - En términos de calidad, ambas técnicas producen resultados similares\"\n",
    "    )\n",
    "    plt.text(0, 0.5, conclusion_text, ha='left', va='center', fontsize=10,\n",
    "             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8, pad=10))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "visualizar_resultados(df, tiempo_manual, tiempo_opencv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
